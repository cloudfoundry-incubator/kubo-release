#!/bin/bash -ex

NAME="${0##*/}"

export PATH=/var/vcap/packages/kubernetes/bin/:/var/vcap/packages/docker/sbin/:/var/vcap/packages/socat/bin/:$PATH

RUN_DIR=/var/vcap/sys/run/kubernetes
PIDFILE=$RUN_DIR/kubelet.pid
LOG_DIR=/var/vcap/sys/log/kubelet
DATA_DIR=/var/vcap/store/kubernetes
DOCKER_SOCKET=unix:///var/vcap/sys/run/docker/docker.sock

if [ -e /var/vcap/jobs/cloud-provider/bin/cloud-provider_utils ]; then
  . /var/vcap/jobs/cloud-provider/bin/cloud-provider_utils
  set_cloud_provider
  cloud_config="/var/vcap/jobs/cloud-provider/config/cloud-provider.ini"
else
  cloud_config=""
  cloud_provider=""
fi

<%
  labels = ""
  if ! p("labels").empty?
    labels = "," + p("labels").map {|k,v| "#{k}=#{v}"}.join(",") 
  end
%>

# shellcheck disable=SC1091
. /var/vcap/packages/pid_utils/pid_utils.sh

setup_directories() {
  mkdir -p "$RUN_DIR" "$LOG_DIR" "$DATA_DIR"
  chown -R vcap:vcap "$RUN_DIR" "$LOG_DIR" "$DATA_DIR"
}

send_process_stdout_to_logfile() {
  exec 1>> "$LOG_DIR/$NAME.stdout.log"
}

send_process_stderr_to_logfile() {
  exec 2>> "$LOG_DIR/$NAME.stderr.log"
}

start_kubelet() {

  ln -s -f /var/vcap/jobs/kubelet/packages/cni/bin/nsenter /usr/bin/nsenter

  if [ "gce" == "$cloud_provider" ]; then
    hostname_override=$(curl http://metadata.google.internal/computeMetadata/v1/instance/name -H "Metadata-Flavor: Google")
  else
    hostname_override=<%= spec.ip %>
  fi

<% if_p('http_proxy') do |http_proxy| %>
export http_proxy=<%= http_proxy %>
<% end %>

<% if_p('no_proxy') do |no_proxy| %>
export no_proxy=<%= no_proxy %>
# also use NO_PROXY since this fix is not in k8s we use yet: https://github.com/kubernetes/kubernetes/commit/92350f336b7aec303ba502c785d13f0cab1ad7f8#diff-1cb1608abe317a2c9acd24f738bc4837
export NO_PROXY=<%= no_proxy %>
<% end %>

  kubelet \
    --allow-privileged=true \
    --cloud-provider=${cloud_provider} \
    --cloud-config="${cloud_config}" \
    --cluster-dns=10.100.200.10 \
    --cluster-domain=cluster.local \
    --container-runtime=docker \
    --docker="${DOCKER_SOCKET}" \
    --docker-endpoint="${DOCKER_SOCKET}" \
    --fail-swap-on=false \
    --hostname-override=${hostname_override} \
    --kubeconfig=/var/vcap/jobs/kubeconfig/config/kubeconfig-kubelet \
    --serialize-image-pulls=false \
    --tls-cert-file=/var/vcap/jobs/kubelet/config/kubelet.pem \
    --tls-private-key-file=/var/vcap/jobs/kubelet/config/kubelet-key.pem \
    --network-plugin=cni \
    --cni-bin-dir=/var/vcap/jobs/kubelet/packages/cni/bin \
    <% if_p('kube-reserved') do |kube_reserved| %>--kube-reserved="<%= kube_reserved %>"<% end %> \
    <% if_p('system-reserved') do |system_reserved| %>--system-reserved="<%= system_reserved %>"<% end %> \
    <% if_p('eviction-hard') do |eviction_hard| %>--eviction-hard="<%= eviction_hard %>"<% end %> \
    --require-kubeconfig=true \
    --v=2 \
    --node-labels=spec.ip=<%= spec.ip %><%= labels %> \
  1>> $LOG_DIR/kubelet.stdout.log \
  2>> $LOG_DIR/kubelet.stderr.log
}

stop_kubelet() {
  kill_and_wait "$PIDFILE"
}

pid() {
  head -1 "$PIDFILE"
}

stop_associated_logging_processes() {
  # shellcheck disable=SC2046
  pkill -g $(get_group_pid)
}

get_group_pid() {
  ps -ho pgrp "$(pid)"
}


case $1 in

  start)

    setup_directories
    send_process_stdout_to_logfile
    send_process_stderr_to_logfile

    pid_guard "$PIDFILE" "Kubelet"

    echo $$ > $PIDFILE
    start_kubelet
    ;;

  stop)
    stop_associated_logging_processes
    stop_kubelet
    ;;

  *)
    echo "Usage: $0 {start|stop}"
    ;;

esac
