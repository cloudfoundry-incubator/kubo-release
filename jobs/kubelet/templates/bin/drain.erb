#!/usr/bin/env bash
# vi: ft=sh

[ -z "$DEBUG" ] || set -x

set -eu

export PATH=/var/vcap/packages/kubernetes/bin:$PATH

LOG_DIR=/var/vcap/sys/log/kubelet
PIDFILE=/var/vcap/sys/run/kubernetes/kubelet.pid

trap ensure_safe_exit EXIT

main() {
  send_process_stdout_to_logfile_and_syslog
  send_process_stderr_to_logfile_and_syslog
  check_if_pidfile_exists
  check_if_pid_is_running
  if ! drain_kubelet; then
    fail_if_master_is_running
  fi
}

ensure_safe_exit() {
  exit_code=$?
  if [[ $exit_code -ne 0 ]]; then
    echo "Kubelet drain failed"
    exit $exit_code
  fi
  echo 0 >&3
}

save_stdout_to_fd3() {
  exec 3>&1
}

send_process_stdout_to_logfile_and_syslog() {
  save_stdout_to_fd3
  exec 1>> "$LOG_DIR/drain.stdout.log"
}

send_process_stderr_to_logfile_and_syslog() {
  exec 2>> "$LOG_DIR/drain.stderr.log"
}

check_if_pid_is_running() {
  local pid
  pid=$(head -1 "$PIDFILE")
  if ! pid_is_running? "${pid}"; then
    echo "$(date) -- Process from pidfile not running, so not attempting to drain."
    exit_with_code 0
  fi
}

fail_if_master_is_running() {
  local ATTEMPTS_REMAINING=100
  local cacert=/var/vcap/jobs/kubelet/config/ca.pem
  local auth_header='Authorization: Bearer <%= p("drain-api-token")  %>'
  while true; do
    if curl -sS https://master.cfcr.internal:8443/healthz -H "$auth_header" --fail --cacert "$cacert" --connect-timeout 2 > /dev/null; then
      exit 1
    else
      ATTEMPTS_REMAINING=$(( ATTEMPTS_REMAINING - 1 ))
      if [[ "$ATTEMPTS_REMAINING" -eq 0 ]]; then
        echo 'Master seems to be down'
        echo 'Assuming this is a bosh delete-deployment, the drain failure will be ignored.'
        exit
      fi
      sleep 1
    fi
  done
}

pid_is_running?() {
  declare pid="$1"
  ps -p "${pid}" >/dev/null 2>&1
}

check_if_pidfile_exists() {
  if [ ! -e $PIDFILE ]; then
    echo "$(date) -- Pidfile not found, so not attempting to drain."
    exit_with_code 0
  fi
}

drain_kubelet() {
  local node_name=$(kubectl --kubeconfig /var/vcap/jobs/kubelet/config/kubeconfig-drain get nodes -o wide -L spec.ip | grep "<%= spec.ip %>" | awk '{print $1}')
  kubectl --kubeconfig /var/vcap/jobs/kubelet/config/kubeconfig-drain drain "${node_name}" --grace-period 10 --force --delete-local-data  --ignore-daemonsets
}

kill_node() {
  kill -9 $(head -1 "$PIDFILE")
  rm -f $PIDFILE
}

main
